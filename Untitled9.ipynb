{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKwW5rNTL3xdBTsBu+vDux",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dikchik9100/genome/blob/main/Untitled9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "NIqYEJPK1Nvw",
        "outputId": "52b7246c-bab5-4ea3-e6d9-641e39c708a1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Could not fetch enough tumor/normal files. Try increasing size or different project.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2053286220.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;31m# 1) Query a small, balanced subset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m     tumor_ids, normal_ids = query_gdc_file_ids(project=\"TCGA-BRCA\", workflow=\"HTSeq - FPKM\",\n\u001b[0m\u001b[1;32m    171\u001b[0m                                                max_tumor=60, max_normal=60)\n\u001b[1;32m    172\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Tumor files: {len(tumor_ids)}, Normal files: {len(normal_ids)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2053286220.py\u001b[0m in \u001b[0;36mquery_gdc_file_ids\u001b[0;34m(project, workflow, max_tumor, max_normal)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtumor_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormal_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Could not fetch enough tumor/normal files. Try increasing size or different project.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtumor_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormal_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Could not fetch enough tumor/normal files. Try increasing size or different project."
          ]
        }
      ],
      "source": [
        "# pip install requests pandas numpy scikit-learn tqdm\n",
        "import os, io, json, tarfile, tempfile, shutil\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "GDC_FILES_URL = \"https://api.gdc.cancer.gov/files\"\n",
        "GDC_DATA_URL = \"https://api.gdc.cancer.gov/data\"\n",
        "\n",
        "def query_gdc_file_ids(project=\"TCGA-BRCA\",\n",
        "                       workflow=\"HTSeq - FPKM\",\n",
        "                       max_tumor=60,\n",
        "                       max_normal=60):\n",
        "    filters = {\n",
        "        \"op\": \"and\",\n",
        "        \"content\": [\n",
        "            {\"op\": \"in\", \"content\": {\"field\": \"project.project_id\", \"value\": [project]}},\n",
        "            {\"op\": \"in\", \"content\": {\"field\": \"data_category\", \"value\": [\"Transcriptome Profiling\"]}},\n",
        "            {\"op\": \"in\", \"content\": {\"field\": \"data_type\", \"value\": [\"Gene Expression Quantification\"]}},\n",
        "            {\"op\": \"in\", \"content\": {\"field\": \"analysis.workflow_type\", \"value\": [workflow]}},\n",
        "            # sample type filter via cases.samples.sample_type\n",
        "            {\"op\": \"in\", \"content\": {\"field\": \"cases.samples.sample_type\", \"value\": [\"Primary Tumor\",\"Solid Tissue Normal\"]}}\n",
        "        ]\n",
        "    }\n",
        "    params = {\n",
        "        \"filters\": json.dumps(filters),\n",
        "        \"fields\": \"file_id,file_name,cases.submitter_id,cases.samples.sample_type\",\n",
        "        \"format\": \"JSON\",\n",
        "        \"size\": \"2000\"\n",
        "    }\n",
        "    r = requests.get(GDC_FILES_URL, params=params, timeout=120)\n",
        "    r.raise_for_status()\n",
        "    hits = r.json()[\"data\"][\"hits\"]\n",
        "\n",
        "    tumor_ids, normal_ids = [], []\n",
        "    for h in hits:\n",
        "        # some files have multiple samples listed; pick any that matches\n",
        "        sample_types = {s.get(\"sample_type\",\"\") for c in h.get(\"cases\",[]) for s in c.get(\"samples\",[])}\n",
        "        fid = h[\"file_id\"]\n",
        "        if \"Primary Tumor\" in sample_types and len(tumor_ids) < max_tumor:\n",
        "            tumor_ids.append(fid)\n",
        "        elif \"Solid Tissue Normal\" in sample_types and len(normal_ids) < max_normal:\n",
        "            normal_ids.append(fid)\n",
        "        if len(tumor_ids) >= max_tumor and len(normal_ids) >= max_normal:\n",
        "            break\n",
        "\n",
        "    if len(tumor_ids) == 0 or len(normal_ids) == 0:\n",
        "        raise RuntimeError(\"Could not fetch enough tumor/normal files. Try increasing size or different project.\")\n",
        "    return tumor_ids, normal_ids\n",
        "\n",
        "def download_gdc_files(file_ids, out_dir):\n",
        "    # GDC data endpoint can accept multiple ids; weâ€™ll batch if needed\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    batch_size = 100  # safe batch\n",
        "    all_downloaded = []\n",
        "    for i in range(0, len(file_ids), batch_size):\n",
        "        batch = file_ids[i:i+batch_size]\n",
        "        params = {\"ids\": \",\".join(batch)}\n",
        "        # POST with JSON body is the recommended approach; GET with ids query also works\n",
        "        r = requests.post(GDC_DATA_URL, data=json.dumps({\"ids\": batch}), headers={\"Content-Type\":\"application/json\"}, timeout=600, stream=True)\n",
        "        r.raise_for_status()\n",
        "        # response is a tar.gz with multiple files\n",
        "        with tarfile.open(fileobj=io.BytesIO(r.content), mode=\"r:gz\") as tar:\n",
        "            for member in tar.getmembers():\n",
        "                if member.isfile():\n",
        "                    tar.extract(member, path=out_dir)\n",
        "                    all_downloaded.append(os.path.join(out_dir, member.name))\n",
        "    return all_downloaded\n",
        "\n",
        "def load_htseq_fpkm(folder, label):\n",
        "    \"\"\"\n",
        "    Each HTSeq - FPKM file: TSV with gene_id and FPKM value columns.\n",
        "    Return dataframe: rows=genes, cols=[sample], values=FPKM\n",
        "    \"\"\"\n",
        "    dfs = []\n",
        "    for fname in os.listdir(folder):\n",
        "        path = os.path.join(folder, fname)\n",
        "        if not os.path.isfile(path):\n",
        "            continue\n",
        "        try:\n",
        "            df = pd.read_csv(path, sep=\"\\t\", header=None, names=[\"gene_id\",\"fpkm\"], usecols=[0,1])\n",
        "        except Exception:\n",
        "            continue\n",
        "        # Keep only Ensembl gene rows (filter out special rows like __no_feature)\n",
        "        df = df[df[\"gene_id\"].str.startswith(\"ENSG\")]\n",
        "        # make sample column from file name\n",
        "        sample_id = os.path.splitext(os.path.basename(path))[0]\n",
        "        df = df.set_index(\"gene_id\")\n",
        "        df.columns = [sample_id]\n",
        "        dfs.append(df)\n",
        "    if not dfs:\n",
        "        raise RuntimeError(f\"No HTSeq FPKM files parsed in {folder}\")\n",
        "    mat = pd.concat(dfs, axis=1).fillna(0.0)\n",
        "    labels = pd.Series(label, index=mat.columns, name=\"label\")\n",
        "    return mat, labels\n",
        "\n",
        "def build_dataset(tumor_ids, normal_ids):\n",
        "    with tempfile.TemporaryDirectory() as tmp:\n",
        "        tumor_dir = os.path.join(tmp, \"tumor\")\n",
        "        normal_dir = os.path.join(tmp, \"normal\")\n",
        "        os.makedirs(tumor_dir, exist_ok=True)\n",
        "        os.makedirs(normal_dir, exist_ok=True)\n",
        "\n",
        "        print(\"Downloading tumor files...\")\n",
        "        download_gdc_files(tumor_ids, tumor_dir)\n",
        "        print(\"Downloading normal files...\")\n",
        "        download_gdc_files(normal_ids, normal_dir)\n",
        "\n",
        "        Xt, yt = load_htseq_fpkm(tumor_dir, label=1)   # 1 = disease\n",
        "        Xn, yn = load_htseq_fpkm(normal_dir, label=0)  # 0 = healthy\n",
        "\n",
        "        # align genes\n",
        "        common_genes = Xt.index.intersection(Xn.index)\n",
        "        Xt = Xt.loc[common_genes]\n",
        "        Xn = Xn.loc[common_genes]\n",
        "\n",
        "        X = pd.concat([Xt, Xn], axis=1)\n",
        "        y = pd.concat([yt, yn])\n",
        "\n",
        "        # transpose to samples x features\n",
        "        X = X.T\n",
        "        # log1p transform to stabilize variance\n",
        "        X = np.log1p(X)\n",
        "        return X, y, common_genes.tolist()\n",
        "\n",
        "def train_model(X, y):\n",
        "    # High-dim: use PCA to 100 comps then logistic regression\n",
        "    pipeline = Pipeline([\n",
        "        (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
        "        (\"pca\", PCA(n_components=min(100, X.shape[1]))),\n",
        "        (\"clf\", LogisticRegression(\n",
        "            penalty=\"l2\",\n",
        "            solver=\"liblinear\",\n",
        "            max_iter=5000,\n",
        "            class_weight=\"balanced\",\n",
        "            random_state=42\n",
        "        ))\n",
        "    ])\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    scores = cross_val_score(pipeline, X, y, cv=cv, scoring=\"accuracy\")\n",
        "    print(f\"CV accuracy: mean={scores.mean():.3f}, std={scores.std():.3f}\")\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.25, stratify=y, random_state=42\n",
        "    )\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "    print(\"Holdout accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(\"Classification report:\\n\", classification_report(y_test, y_pred))\n",
        "    return pipeline\n",
        "\n",
        "def predict_person(model, gene_names, person_gene_to_value):\n",
        "    # Build feature vector aligned to training gene order\n",
        "    x = np.zeros((1, len(gene_names)), dtype=float)\n",
        "    idx = {g:i for i,g in enumerate(gene_names)}\n",
        "    for g, v in person_gene_to_value.items():\n",
        "        if g in idx:\n",
        "            x[0, idx[g]] = float(v)\n",
        "    return model.predict(x)[0], (model.predict_proba(x)[0].tolist() if hasattr(model,\"predict_proba\") else None)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 1) Query a small, balanced subset\n",
        "    tumor_ids, normal_ids = query_gdc_file_ids(project=\"TCGA-BRCA\", workflow=\"HTSeq - FPKM\",\n",
        "                                               max_tumor=60, max_normal=60)\n",
        "    print(f\"Tumor files: {len(tumor_ids)}, Normal files: {len(normal_ids)}\")\n",
        "\n",
        "    # 2) Download + assemble matrix\n",
        "    X, y, gene_order = build_dataset(tumor_ids, normal_ids)\n",
        "    print(f\"Matrix: samples={X.shape[0]}, genes={X.shape[1]}\")\n",
        "\n",
        "    # 3) Train + evaluate\n",
        "    model = train_model(X, y)\n",
        "\n",
        "    # 4) Example prediction for a person (fake values for demonstration)\n",
        "    example = {gene_order[0]: 5.0, gene_order[1]: 0.8, gene_order[2]: 2.1}\n",
        "    pred, proba = predict_person(model, gene_order, example)\n",
        "    print(\"Predicted label (1=disease, 0=healthy):\", int(pred))\n",
        "    if proba:\n",
        "        print(\"Class probabilities [p(0), p(1)]:\", proba)"
      ]
    }
  ]
}