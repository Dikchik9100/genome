{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObnS47+XuYE26G6lLL6LR5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dikchik9100/genome/blob/main/Untitled10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8RV43V5B5Vjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# leukemia_logreg_openml.py\n",
        "import openml\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def fetch_leukemia_dataset(min_instances=60, min_features=1000):\n",
        "    \"\"\"\n",
        "    Search OpenML for a leukemia-like gene-expression dataset (binary) and load it.\n",
        "    Returns: X (DataFrame), y (Series), ds_meta (OpenML dataset object)\n",
        "    \"\"\"\n",
        "    print(\"Searching OpenML for candidate leukemia datasets (this may take a few seconds)...\")\n",
        "    datasets = openml.datasets.list_datasets(output_format=\"dataframe\")\n",
        "\n",
        "    # Filter heuristics: name contains 'leukemia', binary class, enough instances and many features\n",
        "    candidates = datasets[\n",
        "        datasets['name'].str.contains('leukemia', case=False, na=False)\n",
        "        & (datasets['NumberOfClasses'] == 2)\n",
        "        & (datasets['NumberOfInstances'] >= min_instances)\n",
        "        & (datasets['NumberOfFeatures'] >= min_features)\n",
        "    ].sort_values(by='NumberOfInstances', ascending=False)\n",
        "\n",
        "    if candidates.empty:\n",
        "        raise RuntimeError(\n",
        "            \"No suitable candidate found on OpenML with those filters. \"\n",
        "            \"You can relax min_instances/min_features or search manually on openml.org.\"\n",
        "        )\n",
        "\n",
        "    did = int(candidates.iloc[0]['did'])\n",
        "    ds = openml.datasets.get_dataset(did)\n",
        "    print(f\"Selected dataset: {candidates.iloc[0]['name']} (did={did})\")\n",
        "\n",
        "    # ds.get_data may return (X, y, categorical_indicator, attribute_names)\n",
        "    X, y, categorical_indicator, attribute_names = ds.get_data(target=ds.default_target_attribute)\n",
        "\n",
        "    # Convert X to DataFrame with appropriate columns\n",
        "    # attribute_names sometimes includes the target name at the end â€” guard against off-by-one\n",
        "    if isinstance(X, pd.DataFrame):\n",
        "        X_df = X.copy()\n",
        "    else:\n",
        "        # attribute_names might be None/incorrect: construct range names if needed\n",
        "        if attribute_names is None:\n",
        "            cols = [f\"f{i}\" for i in range(X.shape[1])]\n",
        "        else:\n",
        "            # If attribute_names length equals X.shape[1] + 1, drop last one (assumed target)\n",
        "            if len(attribute_names) == X.shape[1] + 1:\n",
        "                cols = attribute_names[:-1]\n",
        "            else:\n",
        "                cols = attribute_names\n",
        "        X_df = pd.DataFrame(X, columns=cols)\n",
        "\n",
        "    # Convert y to Series and encode labels (e.g., 'ALL'/'AML' -> 0/1)\n",
        "    y_ser = pd.Series(y, name='target')\n",
        "    if y_ser.dtype == object or y_ser.dtype.name == 'category':\n",
        "        le = LabelEncoder()\n",
        "        y_enc = pd.Series(le.fit_transform(y_ser), name='target')\n",
        "        class_labels = le.classes_\n",
        "    else:\n",
        "        y_enc = y_ser.astype(int)\n",
        "        class_labels = np.unique(y_enc)\n",
        "\n",
        "    # Ensure numeric features (coerce non-numeric to numeric, drop columns that are all NaN)\n",
        "    X_df = X_df.apply(pd.to_numeric, errors='coerce')\n",
        "    nan_cols = X_df.columns[X_df.isna().all()].tolist()\n",
        "    if nan_cols:\n",
        "        print(f\"Warning: dropping {len(nan_cols)} columns that are entirely NaN.\")\n",
        "        X_df = X_df.drop(columns=nan_cols)\n",
        "\n",
        "    # Drop rows with any NaNs (rare for proper gene-expression datasets)\n",
        "    rows_before = X_df.shape[0]\n",
        "    merged = pd.concat([X_df, y_enc], axis=1).dropna()\n",
        "    if merged.shape[0] < rows_before:\n",
        "        print(f\"Dropping {rows_before - merged.shape[0]} rows due to NaNs.\")\n",
        "    X_df = merged.drop(columns=['target'])\n",
        "    y_enc = merged['target']\n",
        "\n",
        "    return X_df, y_enc, ds\n",
        "\n",
        "def train_and_evaluate(X, y, random_state=42):\n",
        "    pipeline = Pipeline([\n",
        "        ('scaler', StandardScaler(with_mean=True, with_std=True)),\n",
        "        ('clf', LogisticRegression(\n",
        "            penalty='l2',\n",
        "            solver='liblinear',    # liblinear works well for small datasets\n",
        "            max_iter=5000,\n",
        "            class_weight='balanced',\n",
        "            random_state=random_state\n",
        "        ))\n",
        "    ])\n",
        "\n",
        "    print(f\"Data shape: samples={X.shape[0]}, features={X.shape[1]}\")\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
        "    print(\"Running 5-fold stratified cross-validation...\")\n",
        "    cv_scores = cross_val_score(pipeline, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
        "    print(f\"CV accuracy: mean={cv_scores.mean():.4f}, std={cv_scores.std():.4f}\")\n",
        "\n",
        "    # Holdout evaluation\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.25, stratify=y, random_state=random_state\n",
        "    )\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "    print(\"\\nHoldout accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "    return pipeline, X.columns.tolist(), np.unique(y)\n",
        "\n",
        "def predict_for_person(model_pipeline, feature_names, class_labels, person_features_dict):\n",
        "    \"\"\"\n",
        "    person_features_dict: {feature_name: value, ...}\n",
        "    Missing features are filled with 0. Returns (pred_label, prob_dict or None)\n",
        "    \"\"\"\n",
        "    # Build DataFrame with a single row\n",
        "    x_row = pd.DataFrame(np.zeros((1, len(feature_names))), columns=feature_names)\n",
        "    for k, v in person_features_dict.items():\n",
        "        if k in x_row.columns:\n",
        "            try:\n",
        "                x_row.at[0, k] = float(v)\n",
        "            except Exception:\n",
        "                raise ValueError(f\"Value for feature {k} is not numeric: {v}\")\n",
        "        else:\n",
        "            print(f\"Warning: feature '{k}' not found in model feature list; ignoring it.\")\n",
        "\n",
        "    pred = model_pipeline.predict(x_row)[0]\n",
        "    proba = None\n",
        "    if hasattr(model_pipeline, \"predict_proba\"):\n",
        "        p_arr = model_pipeline.predict_proba(x_row)[0]\n",
        "        proba = {str(class_labels[i]): float(p_arr[i]) for i in range(len(class_labels))}\n",
        "    return pred, proba\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        print(\"Downloading leukemia dataset from OpenML...\")\n",
        "        X, y, ds_meta = fetch_leukemia_dataset()\n",
        "    except Exception as e:\n",
        "        print(\"Failed to fetch dataset from OpenML:\", str(e))\n",
        "        print(\"If you are behind a firewall or OpenML is unavailable, please ensure internet access or provide a local CSV.\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    print(f\"\\nLoaded dataset: {ds_meta.name} (did={ds_meta.dataset_id}).\")\n",
        "    model, feature_names, class_labels = train_and_evaluate(X, y)\n",
        "\n",
        "    # Example prediction: set a few probe values; missing probes default to 0\n",
        "    example_input = {\n",
        "        feature_names[0]: 0.5,\n",
        "        feature_names[1]: -1.2,\n",
        "        feature_names[2]: 2.3\n",
        "    }\n",
        "    pred_label, proba = predict_for_person(model, feature_names, class_labels, example_input)\n",
        "    print(\"\\nPredicted disease class (encoded):\", pred_label)\n",
        "    if proba is not None:\n",
        "        print(\"Class probabilities:\", proba)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Q_MXB695fCz",
        "outputId": "ee0342a3-2616-44d1-e2fe-bb102b97f5b5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading leukemia dataset from OpenML...\n",
            "Searching OpenML for candidate leukemia datasets (this may take a few seconds)...\n",
            "Selected dataset: leukemia (did=1104)\n",
            "\n",
            "Loaded dataset: leukemia (did=1104).\n",
            "Data shape: samples=72, features=7129\n",
            "Running 5-fold stratified cross-validation...\n",
            "CV accuracy: mean=0.9448, std=0.0504\n",
            "\n",
            "Holdout accuracy: 0.8333333333333334\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.83      0.87        12\n",
            "           1       0.71      0.83      0.77         6\n",
            "\n",
            "    accuracy                           0.83        18\n",
            "   macro avg       0.81      0.83      0.82        18\n",
            "weighted avg       0.84      0.83      0.84        18\n",
            "\n",
            "\n",
            "Predicted disease class (encoded): 0\n",
            "Class probabilities: {'0': 0.9999906630663873, '1': 9.33693361266593e-06}\n"
          ]
        }
      ]
    }
  ]
}